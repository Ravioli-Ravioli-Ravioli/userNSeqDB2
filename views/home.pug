extends layoutOut.pug

block content
  img.img-rounded(src='assets/SeqTorLogo.png', alt='seqtorrlogo')
  p(align='justify') Genomics research is a field of study that gathers huge amounts of different kinds of data from research institutes around the world. The sheer size of individual datasets and types of data has prompted institutes to make use of huge databases housed at their institutes to cater to these different data types and their research clientele. NCBI currently houses the biggest centralized database of genomic information in the world. A standard genomics workflow consistsof storing a local copy of data pulled from NCBI and then running it locally and then finally pushing it back to NCBI upon publicationor to allow sharing access.Centralization of data places the data in a single point of failure. Mirrors and backups are set up to prevent the effects of this single point of failure and also decreases the load on the main server by bringing the mirrored data closer to partner institutions around the world. However, these collaborators do not necessarily need the whole dump of the genomic database stored locally; they usually just need a subset of the database based on the research they are currently working on stored locally in the region.For example, while both Caucasian and Asian sequences are abundant in the NCBI database, a Filipino research program would probably prefer to store only the Asian sequences in their regional database. And instead of pulling huge data from the main database overseas, the Filipino research institutions need only pull from the much closer regional database.This can be further brought down to the level of institutes. Partner institutes with the appropriate local IT infrastructure can joinin the database pool and choose which data to store locally andshare to researchers in the area. The protein NR database is an example of this: with a sheer size of 90GB at the moment and exponentially increasing every year, local institutions working on the NR database have to constantly download an updated NR database from NCBI every month. This database also consistently grows as these institutions also push to the main database. While 90GB may be feasible to download now from NCBI every month, what will be the case when it reaches the terabyte order?
